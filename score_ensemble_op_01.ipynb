{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드는 한국어 텍스트 데이터를 기반으로 여러 종류의 평가 지표(회귀 및 분류)를 예측하기 위한 딥러닝 모델을 구축하고, 훈련시키며, 평가하는 데 사용됩니다. 구체적인 내용은 다음과 같습니다:\n",
    "\n",
    "1. **모델 정의**: \n",
    "   - `KoBERTRubricScorer`: 한국어 BERT(`KoBERT`) 모델을 사용하여 회귀 작업을 수행하는 모델입니다. 여러 회귀 작업(점수)을 예측합니다.\n",
    "   - `KoBERTRubricClassifier`: `KoBERT`를 사용하여 분류 작업을 수행하는 모델입니다. 다양한 클래스를 분류합니다.\n",
    "   - `KoBERTRubricMTLScorer`: 다중 작업 학습(Multi-Task Learning)을 위한 모델로, 회귀 및 분류 작업을 동시에 수행합니다.\n",
    "   - `KoBERTRubricMTLRegressor`: 다중 회귀 작업을 수행하는 모델로, 여러 회귀 출력을 동시에 예측합니다.\n",
    "\n",
    "2. **데이터셋 및 데이터 로더**:\n",
    "   - `RubricScoringDataset`: 텍스트 데이터셋을 전처리하고, 토크나이징하여 모델이 사용할 수 있는 형식으로 변환합니다. 필요한 경우 데이터 증강을 수행합니다.\n",
    "   - `create_data_loader`: 데이터셋을 배치(batch) 단위로 로드하고, 훈련 및 검증/테스트를 위해 셔플 옵션을 관리합니다.\n",
    "\n",
    "3. **훈련 및 검증 로직**:\n",
    "   - `RubricScorerTrainer`: 모델을 훈련시키고 검증하는 클래스입니다. 각 에폭 동안 훈련 손실과 정확도를 계산하고, 검증 데이터셋에 대해 성능을 평가합니다.\n",
    "\n",
    "4. **앙상블**:\n",
    "   - `RubricScorerEnsemble`: 훈련된 여러 모델의 예측 결과를 앙상블하여 최종 예측 결과를 생성합니다. 여기서는 단순 평균(average) 방식을 사용합니다.\n",
    "\n",
    "5. **메인 함수 (`main`)**:\n",
    "   - 데이터셋을 로드하고 전처리합니다.\n",
    "   - 정의된 모델을 초기화하고 훈련시킵니다.\n",
    "   - 훈련된 모델을 앙상블하여 테스트 데이터에 대한 예측을 수행합니다.\n",
    "   - 평가 함수를 사용하여 모델 성능을 측정하고 결과를 출력합니다.\n",
    "\n",
    "전체적으로 이 코드는 딥러닝 기반의 다중 작업 학습 모델을 구축하고 평가하기 위한 완전한 파이프라인을 제공합니다. 데이터 전처리부터 모델 훈련, 앙상블, 평가에 이르기까지 전체적인 딥러닝 작업 흐름을 다룹니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "[\n",
    "    {\n",
    "        \"prompt\": \"인공지능의 발전이 사회에 미치는 영향에 대해 논하시오.\",\n",
    "        \"rubric\": [\n",
    "            {\"name\": \"내용의 적절성\", \"description\": \"주제와 관련된 내용을 적절히 다루었는가?\", \"max_score\": 5},\n",
    "            {\"name\": \"논리적 구조\", \"description\": \"글의 구조가 논리적으로 잘 조직되었는가?\", \"max_score\": 5},\n",
    "            {\"name\": \"어휘의 다양성\", \"description\": \"다양하고 적절한 어휘를 사용하였는가?\", \"max_score\": 3},\n",
    "            {\"name\": \"문법 및 맞춤법\", \"description\": \"문법 및 맞춤법이 정확한가?\", \"max_score\": 2}\n",
    "        ],\n",
    "        \"response\": \"인공지능의 발전은 사회에 많은 변화를 가져올 것입니다. ...\",\n",
    "        \"scores\": [3, 4, 2, 1]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "from torch.utils.data import DataLoader\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class KoBERTRubricScorer(nn.Module):\n",
    "    def __init__(self, num_tasks, hidden_size=768, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        config = BertConfig.from_pretrained('monologg/kobert')\n",
    "        config.num_labels = num_tasks\n",
    "        self.bert = BertModel.from_pretrained('monologg/kobert', config=config)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.regressor = nn.Linear(hidden_size, num_tasks)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.regressor(pooled_output)\n",
    "        return logits\n",
    "\n",
    "class KoBERTRubricClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size=768, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        config = BertConfig.from_pretrained('monologg/kobert')\n",
    "        config.num_labels = num_classes\n",
    "        self.bert = BertModel.from_pretrained('monologg/kobert', config=config)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "class KoBERTRubricMTLScorer(nn.Module):\n",
    "    def __init__(self, num_tasks, num_classes, hidden_size=768, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        config = BertConfig.from_pretrained('monologg/kobert')\n",
    "        self.bert = BertModel.from_pretrained('monologg/kobert', config=config)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.regression_heads = nn.ModuleList([nn.Linear(hidden_size, 1) for _ in range(num_tasks)])\n",
    "        self.classification_head = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        regression_outputs = [head(pooled_output) for head in self.regression_heads]\n",
    "        regression_outputs = torch.cat(regression_outputs, dim=-1)\n",
    "        classification_output = self.classification_head(pooled_output)\n",
    "        return regression_outputs, classification_output\n",
    "\n",
    "class KoBERTRubricMTLRegressor(nn.Module):\n",
    "    def __init__(self, num_tasks, hidden_size=768, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        config = BertConfig.from_pretrained('monologg/kobert')\n",
    "        self.bert = BertModel.from_pretrained('monologg/kobert', config=config)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.regression_heads = nn.ModuleList([nn.Linear(hidden_size, 1) for _ in range(num_tasks)])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        regression_outputs = [head(pooled_output) for head in self.regression_heads]\n",
    "        regression_outputs = torch.cat(regression_outputs, dim=-1)\n",
    "        return regression_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의\n",
    "class RubricScoringDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length, okt=None, stopwords=None, synonym_dict=None, augment_ratio=0.0):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.okt = okt\n",
    "        self.stopwords = stopwords\n",
    "        self.synonym_dict = synonym_dict\n",
    "        self.augment_ratio = augment_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        prompt = item['prompt']\n",
    "        response = item['response']\n",
    "        rubric_text = ' '.join([f\"{rubric['name']}: {rubric['description']}\" for rubric in item['rubric']])\n",
    "        max_scores = torch.tensor([rubric['max_score'] for rubric in item['rubric']], dtype=torch.float32)\n",
    "\n",
    "        if self.okt is not None and self.stopwords is not None:\n",
    "            tokens = self.okt.morphs(response)\n",
    "            tokens = [token for token in tokens if token not in self.stopwords]\n",
    "            response = ' '.join(tokens)\n",
    "        if self.augment_ratio > 0 and random.random() < self.augment_ratio:\n",
    "            response = self.augment_text(response)\n",
    "\n",
    "        text = f\"{prompt} {response} {rubric_text}\"\n",
    "        inputs = self.tokenizer(text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        labels = torch.tensor(item['scores'], dtype=torch.float32)\n",
    "        return inputs['input_ids'].squeeze(), inputs['attention_mask'].squeeze(), labels, max_scores\n",
    "\n",
    "    def augment_text(self, text):\n",
    "        if self.synonym_dict is not None:\n",
    "            words = text.split()\n",
    "            for i, word in enumerate(words):\n",
    "                if word in self.synonym_dict and random.random() < 0.1:\n",
    "                    words[i] = random.choice(self.synonym_dict[word])\n",
    "            text = ' '.join(words)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 검증 트레이너\n",
    "class RubricScorerTrainer:\n",
    "    def __init__(self, model, train_dataloader, val_dataloader, optimizer, criterion, device):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        self.model.to(self.device)\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            for batch in self.train_dataloader:\n",
    "                input_ids, attention_mask, labels = [data.to(self.device) for data in batch]\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                # 예측된 점수를 max_scores로 제한하는 로직을 추가할 수 있음\n",
    "                # 예: outputs = torch.min(outputs, max_scores)\n",
    "\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                train_correct += self.compute_accuracy(outputs, labels)\n",
    "                train_total += labels.size(0)\n",
    "\n",
    "            train_loss /= len(self.train_dataloader)\n",
    "            train_accuracy = train_correct / train_total if train_total > 0 else None\n",
    "            val_loss, val_accuracy = self.validate()\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy if train_accuracy else '-'}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy if val_accuracy else '-'}\")\n",
    "\n",
    "    def compute_loss(self, outputs, labels):\n",
    "        if isinstance(self.model, (KoBERTRubricClassifier, KoBERTRubricMTLScorer)):\n",
    "            return self.criterion(outputs[-1], labels.long())  # Assumes classification labels are at the end\n",
    "        else:\n",
    "            return self.criterion(outputs, labels)\n",
    "\n",
    "    def compute_accuracy(self, outputs, labels):\n",
    "        if isinstance(self.model, (KoBERTRubricClassifier, KoBERTRubricMTLScorer)):\n",
    "            _, predicted = torch.max(outputs[-1], 1)\n",
    "            return (predicted == labels.long()).sum().item()\n",
    "        return 0  # No accuracy for regression tasks\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_dataloader:\n",
    "                input_ids, attention_mask, labels = [data.to(self.device) for data in batch]\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                val_loss += self.compute_loss(outputs, labels).item()\n",
    "                val_correct += self.compute_accuracy(outputs, labels)\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(self.val_dataloader)\n",
    "        val_accuracy = val_correct / val_total if val_total > 0 else None\n",
    "        return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 클래스 정의\n",
    "class RubricScorerEnsemble:\n",
    "    def __init__(self, models, device):\n",
    "        self.models = models\n",
    "        self.device = device\n",
    "\n",
    "    def predict(self, dataloader):\n",
    "        total_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for model, _ in self.models:\n",
    "                model.to(self.device)\n",
    "                model.eval()\n",
    "                predictions = []\n",
    "                for batch in dataloader:\n",
    "                    input_ids, attention_mask, _ = [data.to(self.device) for data in batch]\n",
    "                    outputs = model(input_ids, attention_mask)\n",
    "                    if isinstance(model, (KoBERTRubricClassifier, KoBERTRubricMTLScorer)):\n",
    "                        predictions.append(torch.softmax(outputs[-1], dim=1).cpu().numpy())  # Classifier prediction\n",
    "                    else:\n",
    "                        predictions.append(outputs.cpu().numpy())  # Regressor prediction\n",
    "                total_predictions.append(np.hstack(predictions))\n",
    "\n",
    "        # Mean ensemble\n",
    "        ensemble_predictions = np.mean(np.array(total_predictions), axis=0)\n",
    "        return ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(dataset, batch_size, shuffle=True):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "def evaluate_classification(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, f1\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train_data.csv')\n",
    "    val_data = pd.read_csv('val_data.csv')\n",
    "    test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "    # 토크나이저 및 전처리 도구 로드\n",
    "    tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
    "    okt = Okt()\n",
    "    stopwords = ['은', '는', '이', '가', '을', '를']\n",
    "    synonym_dict = {'좋아하다': ['즐기다', '기뻐하다'], '훌륭하다': ['우수하다', '뛰어나다']}\n",
    "\n",
    "    # 데이터셋 생성\n",
    "    train_dataset = RubricScoringDataset(train_data, tokenizer, max_length=128, okt=okt, stopwords=stopwords, synonym_dict=synonym_dict, augment_ratio=0.1)\n",
    "    val_dataset = RubricScoringDataset(val_data, tokenizer, max_length=128, okt=okt, stopwords=stopwords)\n",
    "    test_dataset = RubricScoringDataset(test_data, tokenizer, max_length=128, okt=okt, stopwords=stopwords)\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    batch_size = 16\n",
    "    train_dataloader = create_data_loader(train_dataset, batch_size, shuffle=True)\n",
    "    val_dataloader = create_data_loader(val_dataset, batch_size, shuffle=False)\n",
    "    test_dataloader = create_data_loader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "    # 디바이스 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 모델 생성 및 훈련\n",
    "    models = {\n",
    "        \"Rubric Scorer\": KoBERTRubricScorer(num_tasks=3),\n",
    "        \"Rubric Classifier\": KoBERTRubricClassifier(num_classes=5),\n",
    "        \"MTL Rubric Scorer\": KoBERTRubricMTLScorer(num_tasks=3, num_classes=5),\n",
    "        \"MTL Rubric Regressor\": KoBERTRubricMTLRegressor(num_tasks=3)\n",
    "    }\n",
    "\n",
    "    trained_models = {}\n",
    "    num_epochs = 10\n",
    "    for name, model in models.items():\n",
    "        if 'Classifier' in name:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "        trainer = RubricScorerTrainer(model, train_dataloader, val_dataloader, optimizer, criterion, device)\n",
    "        print(f\"Training {name}...\")\n",
    "        trainer.train(num_epochs)\n",
    "        trained_models[name] = model\n",
    "\n",
    "    # 앙상블 설정 및 예측\n",
    "    ensemble = RubricScorerEnsemble(list(trained_models.values()), device)\n",
    "    ensemble_predictions = ensemble.predict(test_dataloader)\n",
    "\n",
    "    # 평가 및 결과 출력\n",
    "    regression_labels = test_data[['score1', 'score2', 'score3']].values\n",
    "    regression_mse = evaluate_regression(regression_labels, ensemble_predictions[:, :3])\n",
    "    print(f\"Ensemble Regression MSE: {regression_mse:.4f}\")\n",
    "\n",
    "    classification_labels = test_data['score4'].values  # 가정: score4는 분류 레이블\n",
    "    classification_predictions = np.argmax(ensemble_predictions[:, 3:], axis=1)  # 가정: 마지막 5개 컬럼이 분류 결과\n",
    "    accuracy, f1 = evaluate_classification(classification_labels, classification_predictions)\n",
    "    print(f\"Ensemble Classification Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Ensemble Classification F1 Score: {f1:.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
